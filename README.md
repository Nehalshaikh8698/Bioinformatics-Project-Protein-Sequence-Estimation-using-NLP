ğŸ§¬ Protein Sequence Estimation using NLP
Deep-Learning Based Missing Residue Prediction with ProtBERT

A full-stack AI system that predicts missing amino acids in protein sequences using advanced Transformer-based NLP models.
Built with Python (ProtBERT), a Node.js backend, and a React frontend for real-time residue completion.

â­ Overview

This project uses ProtBERT (Rostlab/prot_bert) â€” a 420M-parameter protein language model trained on UniRef100 (216M+ sequences) â€” to intelligently fill missing residues.

âœ” Predicts amino acids for masked positions
âœ” Supports FASTA input
âœ” Provides confidence scores
âœ” Full-stack real-time system
âœ” Clean and interactive UI

ğŸš€ Features
ğŸ”¬ AI-Powered Protein Sequence Completion

Predicts missing residues (?, _, X, or masked tokens)

Automatically cleans FASTA headers

Handles noisy or incomplete protein sequences

Returns:

Completed sequence

Top residue predictions

Confidence probabilities

ğŸ§¬ Model Summary
Model	Parameters	Dataset	Architecture
ProtBERT	420M	UniRef100	BERT Transformer
ğŸ—ï¸ Full-Stack Architecture
Layer	Technology
Frontend	React, TailwindCSS, Vite
Backend	Node.js, Express.js
Machine Learning	Python, Transformers, PyTorch
Model	ProtBERT (local model directory)
ğŸ“ Project Structure
<img width="740" height="634" alt="image" src="https://github.com/user-attachments/assets/902fccd9-2c40-4a52-a69f-e2a8944e1c36" />

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone Repository
git clone https://github.com/Nehalshaikh8698/Bioinformatics-Project-Protein-Sequence-Estimation-using-NLP.git

cd PROJECT_NLP

2ï¸âƒ£ Download ProtBERT Model (Required)

GitHub cannot store large ML models, so download manually:

from transformers import AutoTokenizer, AutoModelForMaskedLM

tokenizer = AutoTokenizer.from_pretrained("Rostlab/prot_bert", do_lower_case=False)
model = AutoModelForMaskedLM.from_pretrained("Rostlab/prot_bert")

tokenizer.save_pretrained("./backend/ml_models/protbert")
model.save_pretrained("./backend/ml_models/protbert")

3ï¸âƒ£ Backend Setup (Node.js + Python)
cd backend
npm install
npm start


Backend runs at:
ğŸ‘‰ http://localhost:5000

4ï¸âƒ£ Frontend Setup (React + Vite)
cd frontend
npm install
npm start


Frontend runs at:
ğŸ‘‰ http://localhost:3000

ğŸ§ª API Usage
Predict missing residues:
curl -X POST http://localhost:5000/api/models/fill-missing \
  -H "Content-Type: application/json" \
  -d '{"model":"protbert","sequence":"MKTI?ALSYIF"}'

ğŸ¨ Frontend Highlights

FASTA cleanup

Residue prediction visualization

Confidence score ranking

Dark mode

Fully responsive design

Real-time ML processing via backend

ğŸ“Š Example Output
Input
MK?TI?AL?YI

Output
Completed: MKLTILALRYI
Missing position predictions:
? â†’ L (0.82)
? â†’ T (0.71)
? â†’ R (0.64)

#DEMO:
#HOME PAGE
<img width="1128" height="1039" alt="image" src="https://github.com/user-attachments/assets/1efe3875-3537-4bd3-900a-c67117ec69e0" />

#INPUT PAGE
<img width="1885" height="950" alt="image" src="https://github.com/user-attachments/assets/69a1e3aa-68fb-4134-abb0-54e2adbfc29b" />

#OUPUT PAGE
<img width="944" height="968" alt="image" src="https://github.com/user-attachments/assets/ceb9ed83-baed-4e9d-8db0-d85c571171f3" />



ğŸ§¾ Tech Stack
Frontend

React.js

Tailwind CSS

Lucide Icons

Backend

Node.js

Express.js

Python bridge (child_process)

ML Engine

HuggingFace Transformers

ProtBERT

PyTorch

ğŸ”® Future Enhancements

Support for ProtT5, ESM-2, Ankh models

Multi-mask simultaneous prediction

Batch FASTA file upload

Attention heatmaps

Fine-tuning module

ğŸ§  Research Importance

Protein sequence completion helps in:

Drug discovery

Structural biology

Function prediction

Repairing incomplete experimental datasets

Enhancing annotation pipelines

ğŸ‘¨â€ğŸ’» Author

Nehal Shaikh
AI & DS | Full-Stack Developer | Protein NLP Research

ğŸ”— GitHub: @Nehalshaikh8698
